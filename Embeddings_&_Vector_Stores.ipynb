{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NITHESH2303/Gen-AI-Intensive-Course/blob/main/Embeddings_%26_Vector_Stores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWQla5EyDb-y",
    "outputId": "f34c3828-f84c-422f-e9da-79afcd6685f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beir\n",
      "  Downloading beir-2.2.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting sentence-transformers (from beir)\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pytrec-eval-terrier (from beir)\n",
      "  Downloading pytrec_eval_terrier-0.5.10-cp313-cp313-macosx_10_13_universal2.whl.metadata (1.1 kB)\n",
      "Collecting datasets (from beir)\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets->beir)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting numpy>=1.17 (from datasets->beir)\n",
      "  Downloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets->beir)\n",
      "  Downloading pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets->beir)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets->beir)\n",
      "  Using cached pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting requests>=2.32.2 (from datasets->beir)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting httpx<1.0.0 (from datasets->beir)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets->beir)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets->beir)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets->beir)\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets->beir)\n",
      "  Downloading huggingface_hub-1.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.13/site-packages (from datasets->beir) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets->beir)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting scipy>=1.1.0 (from pytrec-eval-terrier->beir)\n",
      "  Using cached scipy-1.16.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers->beir)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers->beir)\n",
      "  Using cached torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers->beir)\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting Pillow (from sentence-transformers->beir)\n",
      "  Using cached pillow-12.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers->beir)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Downloading aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets->beir)\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets->beir)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets->beir)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets->beir)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets->beir)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets->beir)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.25.0->datasets->beir)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets->beir)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets->beir)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets->beir)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers->beir)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers->beir)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers->beir)\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers->beir)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets->beir)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas->datasets->beir) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets->beir)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets->beir)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers->beir)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers->beir)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Downloading multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->beir)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets->beir) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers->beir)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers->beir)\n",
      "  Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets->beir)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading beir-2.2.0-py3-none-any.whl (77 kB)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading pytrec_eval_terrier-0.5.10-cp313-cp313-macosx_10_13_universal2.whl (137 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Downloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl (34.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.2/34.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.16.3-cp313-cp313-macosx_14_0_arm64.whl (20.9 MB)\n",
      "Using cached torch-2.9.1-cp313-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\n",
      "Using cached pillow-12.0.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Downloading scikit_learn-1.7.2-cp313-cp313-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl (489 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl (288 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Installing collected packages: pytz, mpmath, xxhash, urllib3, tzdata, typing_extensions, tqdm, threadpoolctl, sympy, setuptools, safetensors, regex, pyyaml, pyarrow, propcache, Pillow, numpy, networkx, multidict, MarkupSafe, joblib, idna, hf-xet, h11, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, scipy, requests, pandas, multiprocess, jinja2, httpcore, anyio, aiosignal, torch, scikit-learn, pytrec-eval-terrier, huggingface-hub, httpx, aiohttp, tokenizers, transformers, datasets, sentence-transformers, beir\n",
      "Successfully installed MarkupSafe-3.0.3 Pillow-12.0.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.12.0 attrs-25.4.0 beir-2.2.0 certifi-2025.11.12 charset_normalizer-3.4.4 datasets-4.4.1 dill-0.4.0 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.6 numpy-2.3.5 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 pytrec-eval-terrier-0.5.10 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.16.3 sentence-transformers-5.1.2 setuptools-80.9.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 typing_extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.0-cp39-abi3-macosx_14_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.13/site-packages (from faiss-cpu) (2.3.5)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.13/site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.13.0-cp39-abi3-macosx_14_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.13.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beir\n",
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "AKEGN7psIcgr"
   },
   "outputs": [],
   "source": [
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "import faiss\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytrec_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "CbOPtbfaIfmz"
   },
   "outputs": [],
   "source": [
    "def embedText(texts, model, task, batch_size=5):\n",
    "  if not texts:\n",
    "    return np.array([])\n",
    "\n",
    "  # Get the embedding dimension dynamically from the first embedding\n",
    "  if isinstance(model, SentenceTransformer):\n",
    "    dummy_embedding = model.encode([texts[0]])\n",
    "    embedding_dim = dummy_embedding.shape[1]\n",
    "  else:\n",
    "    # Assume Vertex AI TextEmbeddingModel\n",
    "    inputs = [TextEmbeddingInput(texts[0], task_type=task)]\n",
    "    dummy_embedding = model.get_embeddings(inputs)\n",
    "    embedding_dim = len(dummy_embedding[0].values)\n",
    "\n",
    "  embed_mat = np.zeros((len(texts), embedding_dim))\n",
    "\n",
    "  for batch_start in range(0, len(texts), batch_size):\n",
    "    size = min(len(texts) - batch_start, batch_size)\n",
    "    batch_texts = texts[batch_start:batch_start+size]\n",
    "\n",
    "    # Check if the model is a SentenceTransformer or Vertex AI model\n",
    "    if isinstance(model, SentenceTransformer):\n",
    "      embeddings = model.encode(batch_texts)\n",
    "    else:\n",
    "      # Assume Vertex AI TextEmbeddingModel\n",
    "      inputs = [TextEmbeddingInput(text, task_type=task) for text in batch_texts]\n",
    "      embeddings = model.get_embeddings(inputs)\n",
    "      embeddings = np.array([e.values for e in embeddings])\n",
    "\n",
    "    for i in range(size):\n",
    "      embed_mat[batch_start+i] = embeddings[i]\n",
    "  return embed_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fb936f5d392f40a1a9ab559f5bc03fcb",
      "89211a6db533405daac950122728ed1c",
      "40abe6a4e1924eb49a1c24f1301e4e89",
      "08d548507d8a4b4b979e727bd3bdba81",
      "e8a30c3bffe94bea9fba836774aa1361",
      "98bc346fba674b789ad7ff8e28bb28bb",
      "9dd537f464474f809a7bd0bec836f19a",
      "8fbfc9ae0d5644b380e295abea059b86",
      "f0c521ab3c774147bbf8502a30f0792c",
      "91579c7d95b9464992f527aeca895a2d",
      "0ac839937fe64434850b14379075aff4"
     ]
    },
    "id": "VgMP8-deLqIs",
    "outputId": "ed0ee281-0f00-48b7-bbdd-fb21a5956dc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nfcorpus.zip\"\n",
    "data_path = util.download_and_unzip(url, \"datasets\")\n",
    "# Corpus of text chunks, text queries and “gold” set of query to relevant documents dict\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=\"datasets/nfcorpus\").load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "KwUAbPYzP7rC"
   },
   "outputs": [],
   "source": [
    "import google.colab.auth\n",
    "google.colab.auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "FVhrzxvFMrlY"
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=\"aerobic-amphora-479502-i7\", location=\"asia-south1\")\n",
    "# model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "doc_ids, docs = zip(*[(doc_id, doc['text']) for doc_id, doc in corpus.items()])\n",
    "q_ids, questions = zip(*[(q_id, q) for q_id, q in queries.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgBGfeu_QHTX"
   },
   "source": [
    "# Embed the documents and queries jointly using different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "VKxw5OohPDj8"
   },
   "outputs": [],
   "source": [
    "doc_embeddings = embedText(docs[:100], model, \"RETRIEVAL_DOCUMENT\")\n",
    "index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "index.add(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1kP_EStRyzr",
    "outputId": "76aa191c-1e95-49c0-abfd-4f4f4b9773df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.43, Text: \"AIM OF THE STUDY: The Roselle (Hibiscus sabdariffa) was investigated for its uricosuric effect. MATERIALS AND METHODS: A human model with nine subjects with no history of renal stones (non-renal stone, NS) and nine with a history of renal stones (RS) was used in this study. A cup of tea made from 1.5 g of dry Roselle calyces was provided to subjects twice daily (morning and evening) for 15 days. A clotted blood and two consecutive 24-h urine samples were collected from each subject three times: (1) at baseline (control); (2) on days 14 and 15 during the tea drinking period; and (3) 15 days after the tea drinking was stopped (washout). Serum and 24-h urinary samples were analyzed for uric acid and other chemical compositions related to urinary stone risk factors. RESULTS: All analyzed serum parameters were within normal ranges and similar; between the two groups of subjects and among the three periods. Vis-à-vis the urinary parameters, most of the baseline values for both groups were similar. After taking the tea, the trend was an increase in oxalate and citrate in both groups and uric acid excretion and clearance in the NS group. In the RS group, both uric acid excretion and clearance were significantly increased (p<0.01). When the fractional excretion of uric acid (FEUa) was calculated, the values were clearly increased in both the NS and SF groups after the intake of tea and returned to baseline values in the washout period. These changes were more clearly observed when the data for each subject was presented individually. CONCLUSIONS: Our data demonstrate a uricosuric effect of Roselle calyces. Since the various chemical constituents in Roselle calyces have been identified, the one(s) exerting this uricosuric effect need to be identified.\"\n"
     ]
    }
   ],
   "source": [
    "test_embed = embedText([\"is Water Good for hydration?\", \"when the sun rises\"], model, \"RETRIEVAL_QUERY\")\n",
    "s,q = index.search(test_embed, 2)\n",
    "print(f'Score: {s[0][0]:.2f}, Text: \"{docs[q[0][0]]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "z8MKsweEbuqF"
   },
   "outputs": [],
   "source": [
    "query_embeddings = embedText(questions, model, \"RETRIEVAL_QUERY\")\n",
    "q_scores, q_doc_ids = index.search(query_embeddings, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "EJPaJ_v2bHhT"
   },
   "outputs": [],
   "source": [
    "# Create a dict of query to document scores dict for pytrec evaluation\n",
    "# Multiply scores by -1 for sorting as smaller distance is better score for pytrec eval\n",
    "\n",
    "search_qrels = { q_ids[i] : { doc_ids[_id] : -1*s.item() for _id, s in zip(q_doc_ids[i], q_scores[i])} for i in range(len(q_ids))}\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'ndcg_cut.10','P_1','recall_10'})\n",
    "eval_results = evaluator.evaluate(search_qrels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "tDJdvJZSbC1-",
    "outputId": "459ecdbe-c5d7-4fba-b7d4-dc62d35c6df7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_1</th>\n",
       "      <td>0.037152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_10</th>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <td>0.017675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> float64</label>"
      ],
      "text/plain": [
       "P_1            0.037152\n",
       "recall_10      0.008154\n",
       "ndcg_cut_10    0.017675\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(eval_results, orient='index')\n",
    "df.mean()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJY79Fbf9PDkaL5hNCAsuz",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}